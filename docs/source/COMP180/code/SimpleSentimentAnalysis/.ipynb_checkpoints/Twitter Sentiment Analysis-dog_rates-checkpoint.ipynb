{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple example of sentiment analysis\n",
    "\n",
    "We establish a connection to Twitter, and pull as many tweets as we can from a major account, to perform sentiment analysis. Sentiment is classified as positive, neutral, or negative, based on a tweet's pure text, once all extraneous content (such as URLs etc) has been removed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let's specify which account we want to analyze\n",
    "\n",
    "It's always interesting to look at high profile, frequently used accounts. Write the twitter screen name you want to study below, between the two single quotes, without the @ symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter a Twitter screen name \n",
    "ANALYSE_THIS = \"dog_rates\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, let's get our toolbox ready\n",
    "\n",
    "`tweepy` is a library for accessing Twitter's API  \n",
    "`pandas` is our trusted toolbox for dataframes  \n",
    "`numpy` is the best toolbox for various numerical tasks\n",
    "\n",
    "We also use `display`, `pyplot`, and `seaborn` for various visualization tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General:\n",
    "import tweepy           # To consume Twitter's API\n",
    "import pandas as pd     # To handle data\n",
    "import numpy as np      # For number computing\n",
    "\n",
    "# For plotting and visualization:\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to Twitter\n",
    "Establish API connection to Twitter using `credentials.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My access keys are in ./credentials.py\n",
    "# Importing them in this manner will allow me to \n",
    "# use them as variables, below.\n",
    "from credentials import *    \n",
    "\n",
    "# API setup:\n",
    "def twitter_setup():\n",
    "    \"\"\"\n",
    "    Utility function to setup the Twitter's API\n",
    "    with access keys provided through credentials.py\n",
    "    \"\"\"\n",
    "    # Authentication and access using keys:\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "    # Return API with authentication:\n",
    "    api = tweepy.API(auth)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull data from Twitter\n",
    "\n",
    "The Twitter API allows us to pull only 200 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter content received via API\n",
    "stream = twitter_setup()\n",
    "\n",
    "# method applied on stream:\n",
    "#   .timeline() to specify twitter user and number of tweets to pull\n",
    "#   max 200 tweets for now.\n",
    "tweets = stream.user_timeline(screen_name=ANALYSE_THIS, count=100)\n",
    "\n",
    "print(\"Number of tweets extracted: {}.\\n\".format(len(tweets)))\n",
    "\n",
    "# Show the 10 most recent tweets:\n",
    "print(\"10 recent tweets:\\n\")\n",
    "for tweet in tweets[:10]:\n",
    "    print(tweet.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe\n",
    "\n",
    "The tweet(s) above are objects in the class `tweets` and `.text` one of the class methods. So we need to create dataframes, using these objects, to take advantage of *pandas* tools. We can dissect the structure of the class with \n",
    "`print(dir(tweets[0]))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data frame tdf (Tweets Data Frame) comprises\n",
    "# the text from every item in the tweets collection\n",
    "# and we assign the column label 'Tweets'\n",
    "tdf = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
    "\n",
    "# Display a few elements of tdf to make sure the \n",
    "# conversion worked.\n",
    "display(tdf.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enrich the dataframe\n",
    "\n",
    "The dataframe above shows minimal data, but there is a wealth of information \"hiding\" inside the tweet objects. We extract some of that information to enrich the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to expand tdf with information about:\n",
    "#       len: number of characters in tweet\n",
    "#        ID: tweet's id\n",
    "#      Date: date tweet was sent\n",
    "#    Source: device used to send tweet\n",
    "#     Likes: how many so far\n",
    "#       RTs: number of retweets\n",
    "#\n",
    "# Use numpy's array to add the new columns in the dataframe tdf\n",
    "\n",
    "tdf['len']    = np.array([len(tweet.text) for tweet in tweets])\n",
    "tdf['ID']     = np.array([tweet.id for tweet in tweets])\n",
    "tdf['Date']   = np.array([tweet.created_at for tweet in tweets])\n",
    "tdf['Source'] = np.array([tweet.source for tweet in tweets])\n",
    "tdf['Likes']  = np.array([tweet.favorite_count for tweet in tweets])\n",
    "tdf['RTs']    = np.array([tweet.retweet_count for tweet in tweets])\n",
    "\n",
    "# quick printout to get a sense of what the dataframe looks now\n",
    "display(tdf.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average number of characters per tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averageCharacters = np.mean(tdf['len'])\n",
    "\n",
    "print(\"The lenght's average in tweets: {}\".format(averageCharacters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likes and retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We extract the tweet with more FAVs and more RTs:\n",
    "\n",
    "fav_max = np.max(tdf['Likes'])\n",
    "rt_max  = np.max(tdf['RTs'])\n",
    "\n",
    "fav = tdf[tdf.Likes == fav_max].index[0]\n",
    "rt  = tdf[tdf.RTs == rt_max].index[0]\n",
    "\n",
    "# Max FAVs:\n",
    "print(\"The tweet with more likes is: \\n{}\".format(tdf['Tweets'][fav]))\n",
    "print(\"Number of likes: {}\".format(fav_max))\n",
    "print(\"{} characters.\\n\".format(tdf['len'][fav]))\n",
    "\n",
    "# Max RTs:\n",
    "print(\"The tweet with more retweets is: \\n{}\".format(tdf['Tweets'][rt]))\n",
    "print(\"Number of retweets: {}\".format(rt_max))\n",
    "print(\"{} characters.\\n\".format(tdf['len'][rt]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Times series\n",
    "\n",
    "How do the tweets' characteristics change over time? For example, is there a pattern in the number of characters? The likes? The retweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series for data:\n",
    "# tlen: timeseries of tweets' length (number of characters)\n",
    "# tfav: timeseries of tweets' likes\n",
    "# tret: timeseries of tweets' retweets\n",
    "#\n",
    "# All series below are defined against 'Date' -- hence, timeseries\n",
    "\n",
    "tlen = pd.Series(data=tdf['len'].values, index=tdf['Date'])\n",
    "tfav = pd.Series(data=tdf['Likes'].values, index=tdf['Date'])\n",
    "tret = pd.Series(data=tdf['RTs'].values, index=tdf['Date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot tweet length timeseries\n",
    "Not much pattern here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlen.plot(figsize=(16,4), color='r');\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot timeseries for likes\n",
    "\n",
    "Not much help here; no discernible pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfav.plot(figsize=(16,4), color='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot timeseries for retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tret.plot(figsize=(16,4), color='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where are they sent from?\n",
    "\n",
    "Tweets are sent from a variety of sources (devices), such as desktop applications, smartphones, websites, etc. We look at the `Source` column of our dataframe to see how many different sources are used. We start with an empty array (`sources[]`) and everytime we detect a new source in the dataframe, we add it to this array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all possible sources:\n",
    "sources = []\n",
    "for source in tdf['Source']:\n",
    "    if source not in sources:\n",
    "        sources.append(source)\n",
    "\n",
    "# We print sources list:\n",
    "print(\"Creation of content sources:\")\n",
    "for source in sources:\n",
    "    print(\"* {}\".format(source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pie Chart\n",
    "How often is a source used in comparison to others? A pie-chart will provide some insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a numpy vector mapped to labels:\n",
    "percent = np.zeros(len(sources))\n",
    "\n",
    "# Go through each tweet, check its Source, and increase\n",
    "# the corresponding element of the percent vector\n",
    "for source in tdf['Source']:\n",
    "    for index in range(len(sources)):\n",
    "        if source == sources[index]:\n",
    "            percent[index] += 1\n",
    "            pass\n",
    "\n",
    "percent /= 100 # normalize percent vector to 100.\n",
    "\n",
    "# Pie chart:\n",
    "pie_chart = pd.Series(percent, index=sources, name='Sources')\n",
    "\n",
    "pie_chart\n",
    "\n",
    "pie_chart.plot.pie(fontsize=11, autopct='%.2f', figsize=(6, 6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment analysis\n",
    "\n",
    "We use the `textblob` library to analyze sentiment, since it has a nicely trained classifier already built-in. The sentiment analysis method in `textblob` works well with plain text, so first we must clean up the tweets' text and remove any special characters, emoticons, URLs, etc. We accomplish that with the regular expression package `re`. Note that while `textblob`'s sentiment analysis returns a continuum of real numbers, our function below maps polarity to just three values: -1 for negative tweets, 0 for neutral, and +1 for positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean the text in a tweet by removing \n",
    "    links and special characters using regex.\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "def analize_sentiment(tweet):\n",
    "    '''\n",
    "    Utility function to classify the polarity of a tweet\n",
    "    using textblob.\n",
    "    '''\n",
    "    analysis = TextBlob(clean_tweet(tweet))\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 1\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further enrichment of our dataframe\n",
    "\n",
    "We add one more columb to `tdf` to contain the categorical polarity value, i.e., -1 for negative content, 0 for neutral, +1 for positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a column with the result of the analysis:\n",
    "tdf['Sentiment'] = np.array([ analize_sentiment(tweet) for tweet in tdf['Tweets'] ])\n",
    "\n",
    "# Display the updated dataframe with the new column:\n",
    "display(tdf.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New dataframes\n",
    "\n",
    "We may want to look separately at positive, neutral, or negative content. So we create three new dataframes to contain only positive, neutral, or negative tweets. Positive tweets are stored in dataframe `pos_tweets` which is the result of a selection operation on our original dataframe `tdf` for `Sentiment` values > 0. Similar selection criteria are applied for neutral and negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We construct lists with classified tweets:\n",
    "\n",
    "pos_tweets = [ tweet for index, tweet in enumerate(tdf['Tweets']) if tdf['Sentiment'][index] > 0]\n",
    "neu_tweets = [ tweet for index, tweet in enumerate(tdf['Tweets']) if tdf['Sentiment'][index] == 0]\n",
    "neg_tweets = [ tweet for index, tweet in enumerate(tdf['Tweets']) if tdf['Sentiment'][index] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print percentages:\n",
    "\n",
    "print(\"Percentage of positive tweets: {}%\".format(len(pos_tweets)*100/len(tdf['Tweets'])))\n",
    "print(\"Percentage of neutral tweets: {}%\".format(len(neu_tweets)*100/len(tdf['Tweets'])))\n",
    "print(\"Percentage of negative tweets: {}%\".format(len(neg_tweets)*100/len(tdf['Tweets'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart:\n",
    "\n",
    "sentimentPieData = [len(pos_tweets)*100/len(tdf['Tweets']), len(neu_tweets)*100/len(tdf['Tweets']), len(neg_tweets)*100/len(tdf['Tweets'])]\n",
    "sentimentPieLabels = ['positive','neutral','negative']\n",
    "sentimentPieColors = ['#aaaadd','#dddddd','#ddaaaa']\n",
    "\n",
    "pie_chart = pd.Series(sentimentPieData,index=sentimentPieLabels, name=\"Sentiment\")\n",
    "pie_chart.plot.pie(fontsize=11, autopct='%.2f', colors=sentimentPieColors,figsize=(6, 6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
